{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import umap\n","from sklearn.decomposition import PCA\n","from matplotlib.cm import get_cmap\n","from sklearn import linear_model\n","from sklearn.metrics import median_absolute_error\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from useful_funcs import load_df  # , fft_river_df\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from tqdm import tqdm\n","from tqdm.contrib.concurrent import process_map\n","import time\n","import gc\n","from sklearn.manifold import TSNE\n","\n","start_globals = set(globals().keys())\n","\n","# -- River height --\n","river_depth_df = load_df('ingested_data/river_depth_data.csv')\n","river_depth_df = river_depth_df.interpolate(method='linear').interpolate(\n","    method='linear', limit_direction='backward')\n","\n","# -- Precipitation --\n","precip_df = load_df('ingested_data/precip_data.csv')\n","precip_df2 = load_df('ingested_data/precip_data2.csv')\n","\n","# if na can only make better by looking at next nearest df\n","for riv in list(precip_df):\n","    hashmap_for_orig = precip_df[riv].isna()\n","    precip_df.loc[hashmap_for_orig,\n","                  riv] = precip_df2.loc[hashmap_for_orig, riv]\n","precip_df = precip_df.interpolate(method='linear').interpolate(\n","    method='linear', limit_direction='backward')\n","\n","# -- Temperature --\n","temp_df = load_df('ingested_data/temp_data.csv')\n","temp_df2 = load_df('ingested_data/temp_data2.csv')\n","\n","# if na can only make better by looking at next nearest df\n","for riv in list(temp_df):\n","    hashmap_for_orig = temp_df[riv].isna()\n","    temp_df.loc[hashmap_for_orig,\n","                riv] = temp_df2.loc[hashmap_for_orig, riv]\n","temp_df = temp_df.interpolate(method='linear').interpolate(\n","    method='linear', limit_direction='backward')\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["imperfect_final_rivs = []  # for train and validate\n","with open('eda_results/imperfect_final_rivs.txt', 'r') as in_file:\n","    imperfect_final_rivs = in_file.readline()[:-1].split(', ')\n","perfect_final_rivs = []  # for final test\n","with open('eda_results/perfect_final_rivs.txt', 'r') as in_file:\n","    perfect_final_rivs = in_file.readline()[:-1].split(', ')\n","\n","\n","# df name shortening:\n","# letter 1 = d (river depth), p (precipitation), t (temperature)\n","# letter 2 = i (imperfect), p (perfect)\n","di_df = river_depth_df.loc[:, imperfect_final_rivs]\n","pi_df = precip_df.loc[:, imperfect_final_rivs]\n","ti_df = temp_df.loc[:, imperfect_final_rivs]\n","dp_df = river_depth_df.loc[:, perfect_final_rivs]\n","pp_df = precip_df.loc[:, perfect_final_rivs]\n","tp_df = temp_df.loc[:, perfect_final_rivs]\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n","train_rivs, validate_rivs = train_test_split(\n","    imperfect_final_rivs, test_size=0.33, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dtrain_df = di_df.loc[:, train_rivs]\n","normed_01_d_df = (dtrain_df - dtrain_df.min()) / dtrain_df.max()\n","normed_01_d_df.iloc[:, :5].plot()\n","plt.ylabel('Normalised depth from 0-1')\n","plt.xlabel('Time')\n","plt.show()\n","mean_std_d_df = (dtrain_df - dtrain_df.mean()) / dtrain_df.std()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Check frequencies in data\n","# not clear there is pattern any apart from yearly\n","# fft_river_df(dtrain_df, 'depth')\n","# fft_river_df(pi_df.loc[:, train_rivs], 'precipitation')\n","# fft_river_df(ti_df.loc[:, train_rivs], 'temperature')\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Make training, validate, testing matrices for df in next step\n","slide_train_arr = []    # train features\n","slide_val_arr = []      # validate features\n","slide_test_arr = []      # test features\n","data_days = 20\n","future_days = 14\n","rolling_period = data_days+future_days\n","\n","# Considered this but 2x as fast for much uglier code so changed back\n","# https://stackoverflow.com/questions/47483579/how-to-use-numpy-as-strided-from-np-stride-tricks-correctly/47483615#47483615\n","# def custom_rolling(a, length):\n","#     return np.lib.stride_tricks.as_strided(a, (len(a) - (length-1), length), a.strides*2, writeable=False)\n","\n","\n","def slide_window_riv(riv):\n","    imp = riv in imperfect_final_rivs\n","    d = di_df[riv].rolling(\n","        rolling_period) if imp else dp_df[riv].rolling(rolling_period)\n","    p = pi_df[riv].rolling(\n","        rolling_period) if imp else pp_df[riv].rolling(rolling_period)\n","    t = ti_df[riv].rolling(\n","        rolling_period) if imp else tp_df[riv].rolling(rolling_period)\n","    all_features = []\n","    # sliding window through depth, pressure and temp\n","    for idx, (rd, rp, rt) in enumerate(zip(d, p, t)):\n","        # rolling window initially not full\n","        if len(rd) != rolling_period:\n","            continue\n","        feature_data = np.concatenate(\n","            (rd.values[:data_days], rp.values[:data_days], rt.values[:data_days]))\n","        features = [rd.values[-1], riv, idx] + list(feature_data)\n","        all_features.append(features)\n","    return all_features\n","\n","\n","# https://stackoverflow.com/questions/37804279/how-can-we-use-tqdm-in-a-parallel-execution-with-joblib\n","all_slide_window_data = process_map(slide_window_riv, imperfect_final_rivs + perfect_final_rivs,\n","                                    max_workers=16, chunksize=10)\n","\n","for all_features in tqdm(all_slide_window_data, 'Reassigning river data to correct frame'):\n","    for features in all_features:\n","        riv = features[1]\n","        if riv in train_rivs:\n","            slide_train_arr.append(features)\n","        elif riv in validate_rivs:\n","            slide_val_arr.append(features)\n","        else:\n","            slide_test_arr.append(features)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# https://stackoverflow.com/questions/3543833/how-do-i-clear-all-variables-in-the-middle-of-a-python-script\n","currglobals = list(globals().keys())\n","time.sleep(1)\n","for key in currglobals:\n","    if key not in {'currglobals', 'start_globals', 'slide_train_arr', 'slide_val_arr', 'slide_test_arr', 'data_days', 'future_days', 'rolling_period'} | start_globals:\n","        exec('del ' + key)\n","_ = gc.collect()\n","print('Garbage collected')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# create dfs and sort because all out of order!\n","slide_cols = ['y', 'river', 'river_day']\n","for idx in range(data_days):\n","    slide_cols.append(f'd{idx}')\n","for idx in range(data_days):\n","    slide_cols.append(f'p{idx}')\n","for idx in range(data_days):\n","    slide_cols.append(f't{idx}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train_df = pd.DataFrame(slide_train_arr, columns=slide_cols)\n","print('Training data made')\n","X_train_df.sort_values(by=['river', 'river_day'], inplace=True)\n","print('Training data sorted')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_val_df = pd.DataFrame(slide_val_arr, columns=slide_cols)\n","print('Validation data made')\n","X_val_df.sort_values(by=['river', 'river_day'], inplace=True)\n","print('Validation data sorted')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_test_df = pd.DataFrame(slide_test_arr, columns=slide_cols)\n","print('Test data made')\n","X_test_df.sort_values(by=['river', 'river_day'], inplace=True)\n","print('Test data sorted')\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# cleanup unused data\n","for var_name in ['slide_train_arr', 'slide_val_arr', 'slide_test_arr']:\n","    exec('del ' + var_name)\n","_ = gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# --- LASSO model ---\n","clf = linear_model.Lasso(alpha=0.1)\n","clf = clf.fit(X_train_df.iloc[:, 3:], X_train_df['y'])\n","score = clf.score(X_val_df.iloc[:, 3:], X_val_df['y'])\n","print('R2 score for linear regression model:', score)\n","# - 20 days of data predicting 14 days in future -\n","# R2 score for linear regression model: 0.9992265647557013\n","# - 7 days of data predicting 30 days in future -\n","# R2 score for linear regression model: 0.9989407592400386"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Day 34 = depth what we are predicting\n","# We have depth\n","fig, ax = plt.subplots()\n","plt.plot(clf.coef_)\n","plt.xticks(range(data_days*3)[::5], slide_cols[3:][::5])\n","plt.ylabel('Coefficients')\n","plt.xlabel('Feature names')\n","plt.title(f'Coefficient weights for lasso model with R2={score:.2f}')\n","plt.show()\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pred = clf.predict(X_val_df.iloc[:, 3:])\n","med_abs_err = median_absolute_error(X_val_df['y'], pred)\n","print(f'Median abs error: {med_abs_err:.2f}')\n","# - 20 days of data predicting 14 days in future -\n","# Median abs error: 0.31\n","# - 7 days of data predicting 30 days in future -\n","# Median abs error: 0.37"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# from SML312_P6_classification_methods\n","# doesn't work for millions of entries\n","# https://umap-learn.readthedocs.io/en/latest/benchmarking.html\n","# X_test_emb = TSNE(n_components=2, learning_rate='auto',init='pca', angle=0.65, n_jobs=-1, verbose=1, n_iter=300, perplexity=50, random_state=42).fit_transform(X_train_df.iloc[:, 3:28])\n","# Only use best features from lasso\n","X_train_emb = PCA(n_components=2).fit_transform(X_train_df.iloc[:, 3:28])\n","print('lower dim embedding made, now plotting')\n","plt.scatter(X_train_emb[:, 0], X_train_emb[:, 1], s=3, c=X_train_df['y'])\n","plt.title('True labels for test set if PCA reduced')\n","plt.colorbar()\n","plt.show()\n","\n","print('Finding prediction error')\n","train_pred_pca = clf.predict(X_train_df.iloc[:, 3:])\n","print('Prediction error found, now plotting')\n","\n","plt.scatter(X_train_emb[:, 0], X_train_emb[:, 1],\n","            s=3, c=X_train_df['y']-train_pred_pca)\n","plt.title('True - predicted')\n","plt.colorbar()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rows = 10000  # of 2million\n","umap_reducer = umap.UMAP(n_neighbors=100, n_epochs=200)\n","X_train_emb_umap = umap_reducer.fit_transform(X_train_df.iloc[:rows, 3:28])\n","\n","plt.scatter(X_train_emb[:, 0], X_train_emb[:, 1], s=3,\n","            c=X_train_df['y']-train_pred_pca[:rows])\n","plt.title('True - predicted')\n","plt.colorbar()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}