{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tensorflow.keras.layers import Activation\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.models import Sequential\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import seaborn as sns\n","import tensorflow as tf\n","from useful_funcs import parse_data_dfs, make_timeseries\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","\n","di_df, pi_df, ti_df, dp_df, pp_df, tp_df = parse_data_dfs()\n","imperfect_final_rivs, perfect_final_rivs = list(di_df), list(dp_df)\n","\n","print('Collected all base dataframes')\n","train_rivs, validate_rivs = train_test_split(\n","    imperfect_final_rivs, test_size=0.33, random_state=42)\n","\n","dtrain_df = di_df.loc[:, train_rivs]\n","ptrain_df = pi_df.loc[:, train_rivs]\n","ttrain_df = ti_df.loc[:, train_rivs]\n","\n","print('Transforming dataframes into timeseries dataframe')\n","data_days = 49\n","future_days = 14\n","rivers_to_consider = 50  # up to 1816 rivers but will be slower\n","\n","\n","def slide_window_riv(riv):\n","    rolling_period = data_days+future_days\n","    imp = riv in list(di_df)\n","    d = di_df[riv].rolling(\n","        rolling_period) if imp else dp_df[riv].rolling(rolling_period)\n","    p = pi_df[riv].rolling(\n","        rolling_period) if imp else pp_df[riv].rolling(rolling_period)\n","    t = ti_df[riv].rolling(\n","        rolling_period) if imp else tp_df[riv].rolling(rolling_period)\n","    all_features = []\n","\n","    # sliding window through depth, pressure and temp\n","    for idx, (rd, rp, rt) in enumerate(zip(d, p, t)):\n","        # rolling window initially not full\n","        if len(rd) != rolling_period:\n","            continue\n","        # https://stats.stackexchange.com/questions/35304/how-to-standardize-an-array-if-standard-deviation-is-zero\n","        rd_d = rd.values[:data_days]\n","        rd_m, rd_std = np.mean(rd_d), np.std(rd_d) if np.std(rd_d) != 0 else 1\n","        rp_d = rp.values[:data_days]\n","        rp_m, rp_std = np.mean(rp_d), np.std(rp_d) if np.std(rp_d) != 0 else 1\n","        rt_d = rt.values[:data_days]\n","        rt_m, rt_std = np.mean(rt_d), np.std(rt_d) if np.std(rt_d) != 0 else 1\n","        feature_data = np.concatenate(\n","            ((rd_d-rd_m)/rd_std, (rp_d-rp_m)/rp_std, (rt_d-rt_m)/rt_std))\n","        features = [(rd.values[-1]-rd_m)/rd_std, riv, idx] + list(feature_data)\n","        all_features.append(features)\n","    return all_features\n","\n","\n","all_rivs = list(di_df) + list(dp_df)\n","X_train_df, X_val_df, X_test_df = make_timeseries(\n","    all_rivs[:rivers_to_consider], train_rivs, validate_rivs, slide_window_riv, data_days)\n","X_train_df['year_sin'] = np.sin(\n","    X_train_df['river_day'] * (2 * np.pi / 365.2425))\n","X_train_df['year_cos'] = np.cos(\n","    X_train_df['river_day'] * (2 * np.pi / 365.2425))\n","X_val_df['year_sin'] = np.sin(X_val_df['river_day'] * (2 * np.pi / 365.2425))\n","X_val_df['year_cos'] = np.cos(X_val_df['river_day'] * (2 * np.pi / 365.2425))\n","X_test_df['year_sin'] = np.sin(X_test_df['river_day'] * (2 * np.pi / 365.2425))\n","X_test_df['year_cos'] = np.cos(X_test_df['river_day'] * (2 * np.pi / 365.2425))\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# What input and prediction looks like looks like\n","rowIdx = 42\n","y_point = X_train_df.iloc[rowIdx, :]['y']\n","all_ds = [f'd{idx}' for idx in range(data_days)]\n","all_ps = [f'p{idx}' for idx in range(data_days)]\n","all_ts = [f't{idx}' for idx in range(data_days)]\n","d_points = X_train_df.iloc[rowIdx, :][all_ds].to_list()\n","p_points = X_train_df.iloc[rowIdx, :][all_ps].to_list()\n","t_points = X_train_df.iloc[rowIdx, :][all_ts].to_list()\n","plt.scatter(range(data_days), d_points, label='Depth history')\n","plt.scatter(range(data_days), p_points, label='Precipitation history')\n","plt.scatter(range(data_days), t_points, label='Temperature history')\n","plt.scatter(data_days + future_days, y_point, label='Correct depth')\n","plt.legend()\n","riv_name = X_train_df.iloc[rowIdx, :]['river']\n","plt.title(f'Historical features + target for river {riv_name}')\n","plt.show()\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Baseline model\n","model = Sequential([\n","    Dense(1, input_shape=np.array(X_val_df.columns[3:]).shape)\n","])\n","model.compile(loss=tf.keras.losses.MeanSquaredError(),\n","              optimizer=tf.keras.optimizers.Adam(),\n","              metrics=[tf.keras.metrics.MeanAbsoluteError()])\n","\n","history = model.fit(x=X_train_df.iloc[:, 3:], y=X_train_df.iloc[:, 0], epochs=100,\n","                    batch_size=2000,\n","                    validation_split=0.2)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('Really poor performance')\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model loss (MSE)')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n","\n","plt.plot(history.history['mean_absolute_error'])\n","plt.plot(history.history['val_mean_absolute_error'])\n","plt.title('model accuracy')\n","plt.ylabel('mean absolute error')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["points = 60\n","df = X_train_df\n","predictions = model.predict(x=df.iloc[:, 3:]).reshape(-1)[:points]\n","true_vals = df.iloc[:, 0][:points]\n","plt.scatter(range(points), predictions, label=\"Predicted\")\n","plt.scatter(range(points), true_vals, label=\"True\")\n","plt.legend()\n","plt.title('Predictions of 1 neuron model vs true')\n","plt.xlabel('Day')\n","plt.show()\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# based on https://www.tensorflow.org/tutorials/structured_data/time_series\n","cols = list(X_val_df)[3:]\n","plt.bar(x=range(len(cols)),\n","        height=model.layers[0].kernel[:, 0].numpy())\n","plt.title('Weight of all features in 1 neuron model')\n","plt.ylabel('Feature weights')\n","plt.xlabel('Features')\n","plt.show()\n","\n","# top 10 features\n","top_num = 10\n","basic_coef_ord = np.argsort(np.absolute(model.layers[0].kernel[:, 0].numpy()))\n","new_cols = []\n","for idx in basic_coef_ord[-top_num:][::-1]:\n","    col_name = cols[idx]\n","    col_val = model.layers[0].kernel[:, 0].numpy()[idx]\n","    new_cols.append((col_name, col_val))\n","new_cols.sort(key=lambda x: x[0])\n","plt.bar(x=range(top_num),\n","        height=[b for a, b in new_cols])\n","axis = plt.gca()\n","axis.set_xticks(range(top_num))\n","_ = axis.set_xticklabels([a for a, b in new_cols], rotation=90)\n","plt.title(f'Weight of top {top_num} features in 1 neuron model')\n","plt.ylabel('Feature weights')\n","plt.xlabel('Features')\n","plt.show()\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = Sequential([\n","    # dense layer 1\n","    Dense(units=32, activation='relu'),\n","    Dense(1)\n","])\n",""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}